{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from utils import uniprotRetrieve\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf #Make sure version 1.3.0 is installed\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def cdhit(inputFastaFile, identity=0.9, outputDir=\"\"):\n",
    "    if outputDir and not os.path.exists(outputDir):\n",
    "        os.makedirs(outputDir)\n",
    "    outputFile=inputFastaFile.split(\"/\")[-1].replace(\".fasta\",\"_cdhit.fasta\")\n",
    "    outputFilePath=\"{}{}\".format(outputDir,outputFile)\n",
    "    command = \"cd-hit -i {} -o {} -c {}  -n 3 -M 1500\".format(inputFastaFile,outputFilePath,identity)\n",
    "    cmd = subprocess.Popen(command,\n",
    "                           shell=True,\n",
    "                           stdin=subprocess.PIPE,\n",
    "                          stdout=subprocess.PIPE,\n",
    "                          stderr=subprocess.STDOUT)\n",
    "    cmd.communicate()\n",
    "    return outputFilePath\n",
    "\n",
    "\"\"\" Read in model to generate Unirep vectors\"\"\"\n",
    "# Sync relevant weight files\n",
    "!aws s3 sync --no-sign-request --quiet s3://unirep-public/64_weights/ 64_weights/\n",
    "    \n",
    "# Import the mLSTM babbler model\n",
    "from unirep import babbler64 as babbler\n",
    "\n",
    "# Where model weights are stored.\n",
    "MODEL_WEIGHT_PATH = \"./64_weights\"\n",
    "\n",
    "batch_size = 12\n",
    "b = babbler(batch_size=batch_size, model_path=MODEL_WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biodata Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the dataset,\n",
    "the **UniProt REST API** was used to gather cytoplasmic and periplasmic proteins.\n",
    "To limit the sampling bias, the software **CD-HIT** compressed the proteins sequence information so that only clusters of at most 50 percent sequence identity were left.\n",
    "Finally the sequences were transformed to a fixed length vector representation using **UniRep**.\n",
    "This methods extracts states from an unsupervised trained mLSTM-RNN and combines them into a fixed length UniRep representation.\n",
    "This representation contains essential structural and functional features that can be used by ML algorithms to distinguish between Periplasmic and Cytoplasmic proteins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally, \n",
    "the detection of a signal peptide is used to make this distinction.\n",
    "However it has been observed that the signal peptide itself is insufficient to guarantee periplasmic exportation.\n",
    "Therefore,\n",
    "a dataset was made with unirep vectors using the full periplasmic protein sequence \n",
    "and another one using the sequence with the signal peptide cut off. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cytoplasmic proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain cytoplasmic proteins,\n",
    "the [Uniprot REST api](https://www.uniprot.org/help/api%5Fqueries) was used to perform queries.\n",
    "To limit the dataset a bit, \n",
    "we only included proteins of the **Gammaproteobacteria** taxum.\n",
    "In addition we asked the query only those proteins with an **annotation of being in the Cytoplasm of cytosol**.\n",
    "Finally, as an extra safeguard,\n",
    "proteins **could not have an annotation of containing a signal peptide**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1970892it [08:32, 3846.91it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Download sequences and identifiers\"\"\"\n",
    "QUERY=\"taxonomy:Gammaproteobacteria (locations:(location:cytoplasm) OR locations:(location:cytosol)) NOT annotation:(type:signal)\"\n",
    "FORMAT=\"tab\"\n",
    "FILENAME=\"cytoplasm.tab\"\n",
    "COLUMNS=\"id,sequence\"\n",
    "# Use uniprot REST API to retrieve protein in tab format\n",
    "uniprotRetrieve(FILENAME, format=FORMAT, query=QUERY, columns=COLUMNS)\n",
    "\n",
    "\n",
    "CYTOPLASM = pd.read_csv(FILENAME,sep=\"\\t\")\n",
    "# Write fasta file \n",
    "fastaFile = open(\"cytoplasm.fasta\",\"w\")\n",
    "# Transform tab format to fasta format\n",
    "for i,row in tqdm(CYTOPLASM.iterrows()):\n",
    "    entry = row[\"Entry\"]\n",
    "    sequence = row[\"Sequence\"]\n",
    "    fastaFile.write(\">{}\\n{}\\n\".format(entry,sequence))\n",
    "fastaFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The software **CD-HIT** aligns the different protein sequences in the dataset and calculates the **sequence identity** percentage.\n",
    "Similar clusters were combined into clusters and representatives were chosen \n",
    "so that each representative has at most 50 percent sequence identity with any other representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Use cdhit to obtain dataset of no more than 50 percent sequences identit \"\"\"\n",
    "CYTOPLASM_CDHIT = cdhit(\"cytoplasm.fasta\",identity=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Periplasmic proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar method was used to obtain the Periplasmic protein sequences.\n",
    "This time, \n",
    "the query asked for **annotations of the protein being in the periplasm**,\n",
    "and **having a signal peptide**.\n",
    "The proteins sequences and there signal peptide locations are downloaded into a tab-separated text file.\n",
    "From here,\n",
    "two fasta files were generated:\n",
    "* one including the signal peptide sequence \n",
    "* one excluding the signal peptide sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY=\"taxonomy:Gammaproteobacteria locations:(location:periplasm) annotation:(type:signal)\"\n",
    "FORMAT=\"tab\"\n",
    "FILENAME=\"periplasm.tab\"\n",
    "COLUMNS=\"id,sequence,feature(SIGNAL)\"\n",
    "uniprotRetrieve(FILENAME, format=FORMAT, query=QUERY, columns=COLUMNS)\n",
    "\n",
    "PERIPLASM = pd.read_csv(FILENAME,sep=\"\\t\")\n",
    "PERIPLASM[\"newStart\"]=PERIPLASM[\"Signal peptide\"].apply(lambda x : int(x.split(\";\")[0].split(\"..\")[-1]))\n",
    "# Write fasta file with and without fasta \n",
    "withSP = open(\"periplasm_with_sp.fasta\",\"w\")\n",
    "withoutSP = open(\"periplasm_without_sp.fasta\",\"w\")\n",
    "for i,row in tqdm(PERIPLASM.iterrows()):\n",
    "    entry = row[\"Entry\"]\n",
    "    sequence = row[\"Sequence\"]\n",
    "    newStart = row[\"newStart\"]\n",
    "    withSP.write(\">{}\\n{}\\n\".format(entry,sequence))\n",
    "    withoutSP.write(\">{}\\n{}\\n\".format(entry,sequence[newStart:]))\n",
    "withSP.close()\n",
    "withoutSP.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, **CD-HIT** was used to reduce sampling bias.\n",
    "Threshold was set on **50 percent sequence identity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Use cdhit to obtain dataset of no more than 50 percent sequences identity (without SP) \"\"\"\n",
    "PERIPLASM_WITHOUT_SP_CDHIT = cdhit(\"periplasm_without_sp.fasta\",identity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Use cdhit to obtain dataset of no more than 50 percent sequences identity (with SP) \"\"\"\n",
    "PERIPLASM_WITH_SP_CDHIT = cdhit(\"periplasm_with_sp.fasta\",identity=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Generate unirep vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **UniRep** method was used to generate fixed length vectors.\n",
    "(a more elaborate explanation should come here that stresses the power of unsupervised feature extraction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generate vectors for cytoplasmic proteins \"\"\"\n",
    "\n",
    "with open(\"cytoplasm.fasta\") as f:\n",
    "    lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "cytoplasm=dict()\n",
    "for line in lines:\n",
    "    if line.startswith(\">\"):\n",
    "        ID = line.replace(\">\",\"\")\n",
    "        cytoplasm[ID]=dict()\n",
    "        cytoplasm[ID][\"seq\"]=\"\"\n",
    "    else:\n",
    "        cytoplasm[ID][\"seq\"]+=line\n",
    "\n",
    "FILE=\"cytoplasm.unirep\"\n",
    "if not os.path.exists(FILE):\n",
    "    with open(FILE, 'w'): pass      \n",
    "\n",
    "with open(FILE) as f:\n",
    "    IDS_DONE = [LINE.strip().replace(\">\",\"\") for LINE in f.readlines() if LINE.startswith(\">\")]\n",
    "IDS_TODO = [ID for ID in cytoplasm.keys() if ID not in IDS_DONE]\n",
    "\n",
    "for ID in tqdm(IDS_TODO):\n",
    "    seq = cytoplasm[ID][\"seq\"]\n",
    "    repres = b.get_rep(seq)\n",
    "    #cytoplasm[ID][\"unirep\"]= repres\n",
    "    with open(FILE,\"ab\") as f:\n",
    "        f.write(bytes(\">\"+ID+\"\\n\", 'utf-8'))\n",
    "        np.savetxt(f,repres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generate vectors for periplamic proteins without SP \"\"\"\n",
    "\n",
    "with open(\"periplasm_without_sp_cdhit.fasta\") as f:\n",
    "    lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "periplasm=dict()\n",
    "for line in lines:\n",
    "    if line.startswith(\">\"):\n",
    "        ID = line.replace(\">\",\"\")\n",
    "        periplasm[ID]=dict()\n",
    "        periplasm[ID][\"seq\"]=\"\"\n",
    "    else:\n",
    "        periplasm[ID][\"seq\"]+=line\n",
    "\n",
    "FILE=\"periplasm_without_sp.unirep\"\n",
    "if not os.path.exists(FILE):\n",
    "    with open(FILE, 'w'): pass      \n",
    "\n",
    "with open(FILE) as f:\n",
    "    IDS_DONE = [LINE.strip().replace(\">\",\"\") for LINE in f.readlines() if LINE.startswith(\">\")]\n",
    "IDS_TODO = [ID for ID in periplasm.keys() if ID not in IDS_DONE]\n",
    "\n",
    "for ID in tqdm(IDS_TODO):\n",
    "    seq = periplasm[ID][\"seq\"]\n",
    "    repres = b.get_rep(seq)\n",
    "    #periplasm[ID][\"unirep\"]= repres\n",
    "    with open(FILE,\"ab\") as f:\n",
    "        f.write(bytes(\">\"+ID+\"\\n\", 'utf-8'))\n",
    "        np.savetxt(f,repres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generate vectors for periplamic proteins with SP \"\"\"\n",
    "\n",
    "with open(\"periplasm_with_sp_cdhit.fasta\") as f:\n",
    "    lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "periplasm=dict()\n",
    "for line in lines:\n",
    "    if line.startswith(\">\"):\n",
    "        ID = line.replace(\">\",\"\")\n",
    "        periplasm[ID]=dict()\n",
    "        periplasm[ID][\"seq\"]=\"\"\n",
    "    else:\n",
    "        periplasm[ID][\"seq\"]+=line\n",
    "\n",
    "FILE=\"periplasm_with_sp.unirep\"\n",
    "if not os.path.exists(FILE):\n",
    "    with open(FILE, 'w'): pass      \n",
    "\n",
    "with open(FILE) as f:\n",
    "    IDS_DONE = [LINE.strip().replace(\">\",\"\") for LINE in f.readlines() if LINE.startswith(\">\")]\n",
    "IDS_TODO = [ID for ID in periplasm.keys() if ID not in IDS_DONE]\n",
    "\n",
    "for ID in tqdm(IDS_TODO):\n",
    "    seq = periplasm[ID][\"seq\"]\n",
    "    repres = b.get_rep(seq)\n",
    "    #periplasm[ID][\"unirep\"]= repres\n",
    "    with open(FILE,\"ab\") as f:\n",
    "        f.write(bytes(\">\"+ID+\"\\n\", 'utf-8'))\n",
    "        np.savetxt(f,repres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
